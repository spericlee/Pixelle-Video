# 快速开始

已经完成安装和配置？让我们生成第一个视频吧！

---

## 启动 Web 界面

```bash
# 使用 uv 运行
uv run streamlit run web/app.py
```

浏览器会自动打开 `http://localhost:8501`

---

## 生成你的第一个视频

### 步骤一：检查配置

首次使用时，展开「⚙️ 系统配置」面板，确认已配置：

- **LLM 配置**: 选择 AI 模型（如通义千问、GPT 等）并填入 API Key
- **图像配置**: 配置 ComfyUI 地址或 RunningHub API Key

如果还没有配置，请查看 [配置说明](configuration.md)。

配置好后点击「保存配置」。

---

### 步骤二：输入主题

在左侧栏的「📝 内容输入」区域：

1. 选择「**AI 生成内容**」模式
2. 在文本框中输入一个主题，例如：
   ```
   为什么要养成阅读习惯
   ```
3. （可选）设置场景数量，默认 5 个分镜

!!! tip "主题示例"
    - 为什么要养成阅读习惯
    - 如何提高工作效率
    - 健康饮食的重要性
    - 旅行的意义

---

### 步骤三：配置语音和视觉

在中间栏：

**语音设置**
- 选择 TTS 工作流（默认 Edge-TTS 即可）
- 如需声音克隆，可上传参考音频

**视觉设置**
- 选择图像生成工作流（默认即可）
- 设置图像尺寸（默认 1024x1024）
- 选择视频模板（推荐竖屏 1080x1920）

---

### 步骤四：生成视频

点击右侧栏的「🎬 生成视频」按钮！

系统会显示实时进度：
- 生成文案
- 生成配图（每个分镜）
- 合成语音
- 合成视频

!!! info "生成时间"
    生成一个 5 分镜的视频大约需要 2-5 分钟，具体时间取决于：LLM API 响应速度、图像生成速度、TTS 工作流类型、网络状况

---

### 步骤五：预览视频

生成完成后，视频会自动在右侧栏播放！

你可以看到：
- 📹 视频预览播放器
- ⏱️ 视频时长
- 📦 文件大小
- 🎬 分镜数量
- 📐 视频尺寸

视频文件保存在 `output/` 文件夹中。

---

## 下一步探索

恭喜！你已经成功生成了第一个视频 🎉

接下来你可以：

- **调整风格** - 查看 [自定义视觉风格](../tutorials/custom-style.md) 教程
- **克隆声音** - 查看 [使用参考音频克隆声音](../tutorials/voice-cloning.md) 教程
- **使用 API** - 查看 [API 使用指南](../user-guide/api.md)
- **开发模板** - 查看 [模板开发指南](../user-guide/templates.md)

